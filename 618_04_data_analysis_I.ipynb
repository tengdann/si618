{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 618: Data Manipulation and Analysis\n",
    "## 04 - Univariate Statistics & Visualization\n",
    "\n",
    "### Dr. Chris Teplovs, School of Information, University of Michigan\n",
    "<small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a> This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of today \n",
    "\n",
    "- Announcements -> Upcoming Homework\n",
    "- Comments/Questions/Concerns\n",
    "- Review last week: Aggregation & Grouping\n",
    "- Today: Univariate Statistics  & Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzYmZ_ZRVZ6h"
   },
   "source": [
    "### IMPORTANT: Replace ```?``` in the following code with your uniqname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJ-VtIuoVZ6i"
   },
   "outputs": [],
   "source": [
    "MY_UNIQNAME = 'tengdann'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Aggregation and Grouping----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* use StringIO to create a DataFrame\n",
    "* use the .describe() function\n",
    "* understand .groupby()\n",
    "* understand different types of merges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Gandalf',\n",
    "         'Gimli',\n",
    "         'Frodo',\n",
    "         'Legolas',\n",
    "         'Bilbo',\n",
    "         'Sam',\n",
    "         'Pippin',\n",
    "         'Boromir',\n",
    "         'Aragorn',\n",
    "         'Galadriel',\n",
    "         'Meriadoc',\n",
    "        'Lily']\n",
    "races = ['Maia',\n",
    "         'Dwarf',\n",
    "         'Hobbit',\n",
    "         'Elf',\n",
    "         'Hobbit',\n",
    "         'Hobbit',\n",
    "         'Hobbit',\n",
    "         'Man',\n",
    "         'Man',\n",
    "         'Elf',\n",
    "         'Hobbit',\n",
    "        'Hobbit']\n",
    "magic = [10, 1, 4, 6, 4, 2, 0, 0, 2, 9, 0, np.NaN]\n",
    "aggression = [7, 10, 2, 5, 1, 6, 3, 8, 7, 2, 4, np.NaN ]\n",
    "stealth = [8, 2, 5, 10, 5, 4 ,5, 3, 9, 10, 6, np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name': names,'race':races,'magic':magic,'aggression': aggression,'stealth':stealth})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's say we have another CSV file that contains URLs to Wikipedia pages for some of the LOTR characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv('data/lotr_wikipedia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the original DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the rows are \"aligned\", so we can use the ```concat``` function to concatenate the two DataFrames.\n",
    "Note that we specify the axis to be the columns.  The default is to concatenate by rows, which isn't what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,urls],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great, and it's consistent with what we've used in previous classes.  But what happens if the \n",
    "rows in the two DataFrames don't match up?  Let's load another file that has a slightly different\n",
    "sequence of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "knowledge_building": {
     "cell_groupid": "c04-q4",
     "cell_type": "rcode_answer"
    }
   },
   "outputs": [],
   "source": [
    "urls_wrong_order = pd.read_csv('data/lotr_wikipedia_wrong_order.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,urls_wrong_order],axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a closer look at the name and url columns.  Something's not quite right.\n",
    "\n",
    "We can work around that by using the appropriate indexing and then using the SQL-like ```join``` function. ```.join``` Join columns with other DataFrame either on index or on a key column. By default, ```join``` uses a **left** join, which means the all the values from the \"left\" side are used, whether or not there's a corresponding entry from the \"right\" side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order_names = urls_wrong_order.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.join(urls_wrong_order_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_wrong_order['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_wrong_order,on='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's add some more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a few additional URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_extras = pd.read_csv(\"data/lotr_wikipedia_extras.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's use concat to add the new entries to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_complete = pd.concat([urls,urls_extras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pivot 1](http://www.datasciencemadesimple.com/wp-content/uploads/2017/09/join-or-merge-in-python-pandas-1.png \"pivots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, ```merge``` uses an **\"inner\"** join, which include only those values that exist in both the \"left\" and \"right\" DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_complete,on='name',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A left join, which means the all the values from the **\"left\"** side are used, whether or not there's a corresponding entry from the \"right\" side.  In the example below, note that the url value for \"Lily\" is \"NaN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_complete,on='name',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"opposite\" of a left join is, perhaps unsurprisingly, a **\"right\"** join, in which\n",
    "all the values from the \"right\" side are used, whether or not a corresponding\n",
    "value from the \"left\" side exists. Note in the following example that \"Lily\" has\n",
    "disappeared, and Treebeard and Elrond lack information about \"race\", \"magic\", \"aggression\", and \"stealth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_complete,on='name',how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to \"left\" and \"right\" joins, we have **\"outer\"** joins, which include\n",
    "values from both the \"left\" and \"right\" DataFrames, regardless of whether\n",
    "there are corresponding values in the other DataFrame.  Note that all of \n",
    "\"Lily\", \"Treebeard\" and \"Elrond\" are present in the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_complete,on='name',how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's nice to know how a particular row got added to the resulting DataFrame.  Using **```indicator=True```**\n",
    "allows us to examine this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(urls_complete,how='outer',indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that we used the ```merge``` function from the DataFrame and passed in the other DataFrame as an argument.\n",
    "You can also call the ```merge``` function from pandas directly and pass it the two DataFrames you are merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df,urls_complete,how='outer',indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to start let's make a fake dataset: sales of fruit across US states.\n",
    "# Don't worry about the details here, but basically we'll pretend\n",
    "# this string is a CSV file and use the standard loading ops\n",
    "from io import StringIO\n",
    "\n",
    "TESTDATA=StringIO(\"\"\"State,Retailer,Fruit,Sales\n",
    "MI,Walmart,Apple,100\n",
    "MI,Wholefoods,Apple,150\n",
    "MI,Kroger,Orange,180\n",
    "CA,Walmart,Apple,220\n",
    "CA,Wholefoods,Apple,180\n",
    "CA,Safeway,Apple,220\n",
    "CA,Safeway,Orange,110\n",
    "NY,Walmart,Apple,90\n",
    "NY,Walmart,Orange,80\n",
    "NY,Wholefoods,Orange,120\n",
    "\"\"\")\n",
    "\n",
    "fruit = pd.read_csv(TESTDATA, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (a) What is the total sales for each state?\n",
    "This requires us to group by state, and aggregate sales by taking the sum.\n",
    "\n",
    "The easiest way of doing this if to use `groupby`\n",
    "\n",
    "If you execute groupby on the dataframe what you'll get back is an object called DataFrameGroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fruit.groupby('State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On its own it's a bit useless... it just keeps track of which rows should go into each \"pile\" (where pile here means a unique group for each state)\n",
    "\n",
    "If we ask this object to describe itself, you can see what is inside notice that it threw away all the other columns because they were not numerical.  Only \"Sales\" which is a number, was kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fruit.groupby('State').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# What are the total sales for each state?\n",
    "fruit.groupby('State').sum()  # instead of size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What just happend? A couple of things:\n",
    "- `groupby()` got first executed on `df`, returning an `DataFrameGroupBy` object. This object itself is useless unless coupled with an aggregation function, such as `sum()`, `mean()`, `max()`, `apply()`. We will talk about `apply()` more in the next week.\n",
    "- Then, `sum()` got executed on the `DataFrameGroupBy` object, generating the `DataFrame` object you see above. Notice how the table looks different than the original DataFrame `df`? Here are the differences:\n",
    "  - The `State` column now becomes the index of the DataFrame. The string \"State\" is the name of the index. Notice how the index name is displayed on a lower level than column names.\n",
    "  - Since we performed a `groupby` operation by `State`, so only the unique values of `State` are kept as index.\n",
    "  - Among the other columns, Retailer, Fruit, and Sales, only Sales is kept in the result table. This is because the aggregation function `sum()` only knows how to aggregate numerical values. And only Sales is a numerical column. The other columns are hence dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (b) What is the total sales for each state for each fruit?\n",
    "This requires us to perform `groupby` on two columns. So, we provide a list of column names to the `groupby` function.\n",
    "\n",
    "Don't forget that an aggregation function needs to follow the `groupby` function in order to generate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# What is the total sales for each state for each fruit?\n",
    "fruit.groupby(['State','Fruit']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How is this DataFrame different from the previous one?\n",
    "\n",
    "The biggest different is that this DataFrame has what is called a `MultiIndex` (or hierarchical index), as opposed to a simple index. In this table, the left two \"columns\" are not columns but actually part of the `MultiIndex`, and the `Sales` is the single real \"column\" in the DataFrame. (Running out of terminologies here...)\n",
    "\n",
    "The hierarchical index can be organized in an alternative way if we swapped the order of State and Fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fruit.groupby(['Fruit','State']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (c) Which state has the maximum total sales?\n",
    "This question is not asking about the maximum value, but rather which state holds that maximum. There are multiple ways to do it. A principled way is to use `idxmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which state has the maximum total sales?\n",
    "fruitSalesByState = fruit.groupby('State').sum()\n",
    "print(fruitSalesByState)\n",
    "max_state = fruitSalesByState['Sales'].idxmax()\n",
    "print(\"The state with the maximum sales is: \",max_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to get the sales value of CA again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitSalesByState['Sales'][max_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Which state has the maximum total sales for apples?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Which state has the maximum total sales for apples?\n",
    "# give me apple sellers\n",
    "apples = fruit[fruit.Fruit == 'Apple']\n",
    "apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggr. by state\n",
    "applesByState = apples.groupby('State').sum()\n",
    "applesByState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applesByState.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applesByState.Sales.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applesByState.loc[applesByState.Sales.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above command, `.loc[]` looks up the index label and returns that row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ----------Univariate Statistics----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJ-VtIuoVZ6i"
   },
   "outputs": [],
   "source": [
    "MY_UNIQNAME = 'schenry'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick note about Markdown cells\n",
    "We have encouraged you to use Markdown cells to add text to your notebooks.  Please see \n",
    "https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html for a more complete explanation of the use of Markdown in Jupyter.  You can also examine any of the existing Markdown blocks by clicking on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# So, you want to explore your data...\n",
    "* How can we describe it?\n",
    "* What does it look like?\n",
    "* What sorts of \"preliminary checks\" can we perform on our data? \n",
    " * Why would we want to to this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eyeballing your data: plotting\n",
    "* Introducing [Seaborn](http://seaborn.pydata.org/)\n",
    "> Seaborn is a library for making attractive and informative statistical graphics in Python. It is built on top of matplotlib and tightly integrated with the PyData stack, including support for numpy and pandas data structures and statistical routines from scipy and statsmodels.\n",
    "\n",
    "Um, ok.  How about [some examples](http://seaborn.pydata.org/examples/index.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Think about plotting the relationship between X and Y\n",
    "![](resources/AnscombeData.png)\n",
    "(https://en.wikipedia.org/wiki/Anscombe's_quartet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A nice linear relationship, right?\n",
    "![](resources/AnscombeQ1.png)\n",
    "(https://en.wikipedia.org/wiki/Anscombe's_quartet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Anscombe's Quartet\n",
    "![](resources/AnscombePlot.png)\n",
    "(https://en.wikipedia.org/wiki/Anscombe's_quartet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do we care?\n",
    "\n",
    "* Statistical analysis requires good inputs\n",
    " * Remember Anscombeâ€™s quartet\n",
    " * Which model should we use?\n",
    " * Tendencies/trends/patterns in data are important in picking the right models\n",
    "* Anomalies are important to detect and understand\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Purpose of EDA (broadly)\n",
    "* maximize insight into a data set\n",
    "* uncover underlying structure\n",
    "* extract important variables\n",
    "* detect outliers and anomalies\n",
    "* test underlying assumptions\n",
    "* develop parsimonious models and\n",
    "* determine optimal factor settings.\n",
    "\n",
    "(National Institute of Standards and Technology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our primary goal in this class: understand the _downstream_ statistical analyses enough so that we can make good decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spherical cows\n",
    "The phrase comes from a joke that spoofs the simplifying assumptions that are sometimes used in theoretical physics.\n",
    "\n",
    ">Milk production at a dairy farm was low, so the farmer wrote to the local university, asking for help from academia. A multidisciplinary team of professors was assembled, headed by a theoretical physicist, and two weeks of intensive on-site investigation took place. The scholars then returned to the university, notebooks crammed with data, where the task of writing the report was left to the team leader. Shortly thereafter the physicist returned to the farm, saying to the farmer, \"I have the solution, but it works only in the case of spherical cows in a vacuum\". [Wikipedia](https://en.wikipedia.org/wiki/Spherical_cow)\n",
    "\n",
    "![Spherical cow](resources/Spot_the_cow.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The average weight of a Jersey cow is 1,000 lbs.\n",
    "![](resources/jersey.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's make some spherical cows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The weights of a herd of 80 cows\n",
    "measures = (np.random.standard_normal(80)*150+1000).astype(int)\n",
    "measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">BEGIN Q1: Create some objects of your own\n",
    "Think of some object and some property of that object.  I used cows and their weights.  Pick something that you know something about, and create a NumPy array of some number of them (ideally between 20 and 50000), recording some property.  So you might choose something like the height of undergraduate students, etc.  Pick somethink that will *likely* have a normal distribution (which is probably most things you can think of.</font>\n",
    "\n",
    "First, pick the number that you want and assign it to numberOfObjects, then pick the mean value and assign it to meanOfProperty, and finally pick the variance and assign it to varianceOfProperty.  It doesn't matter what you pick, but if you're unsure pick 1/5 of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfObjects = np.NaN    # change np.NaN to some number between 20 and 50000\n",
    "meanOfProperty = np.NaN     # change np.NaN to the mean value of the property you're interested in\n",
    "standardDeviationOfProperty = meanOfProperty/np.NaN  # change np.NaN to the variance of the property -- try meanOfProperty/5 if you have no idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create some data by asking for a random sample from a normal distribution, scaled so that it matches the mean and variance you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things = np.random.standard_normal(numberOfObjects)*standardDeviationOfProperty+meanOfProperty\n",
    "# And let's say we want integers instead of floats:\n",
    "things = things.astype(int)\n",
    "things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">END Q1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measures of central tendency\n",
    "* Mean\n",
    "* Median \n",
    "* Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mean\n",
    "\n",
    "Add up all the values and divide by the number of values:\n",
    "\n",
    "$$mean = \\frac {\\sum{x_i}} {n}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sum(measures)/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(measures) # find the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Median\n",
    "\n",
    "sort all the numbers and find the one in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "measures = np.sort(measures)\n",
    "measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "measures[len(measures)//2]  # find middle value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Another alternative: Mode\n",
    "\n",
    "* mode = most common value\n",
    "* Unfortunately not in default numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.mode(measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">BEGIN Q2: Calculate the mean, median and mode of your \"things\"\n",
    "\n",
    "Step 1: Just run the following cell (assumes you have some data in an np array called \"things\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats # just in case we didn't already do it\n",
    "\n",
    "thingsMean = 0 # replace 0 with your code\n",
    "thingsMedian = 0 # replace 0 with your code\n",
    "thingsMode = stats.mode(0)[0].item() # replace 0 with your code\n",
    "\n",
    "print(thingsMean, thingsMedian, thingsMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Now, to demonstrate what happens to mean, median and mode when you add an outlier, append some crazy big value to the end of your things.  But let's not mess up our things array, so let's copy it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "outliers = np.nan # change np.nan to some extreme value\n",
    "\n",
    "things2 = things.copy()\n",
    "things2 = np.append(things2,outliers)\n",
    "things2Mean = np.mean(things2).round(2)\n",
    "things2Median = np.median(things2)\n",
    "things2Mode = stats.mode(things2)[0].item()\n",
    "\n",
    "print(things2Mean, things2Median, things2Mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Record, in your own words, what happened to each of the mean, median and mode when you added that value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">END Q2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Measures of dispersion\n",
    "\n",
    "* Percentile cutoffs\n",
    " * Interpercentile range\n",
    "* Variance\n",
    "* Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Percentiles\n",
    "\n",
    "* In a *sorted* list, find the threshold so that data is split\n",
    " * 5th percentile -- bottom 5% of measures below threshold\n",
    " * 25th percentile -- bottom 25% of measures below\n",
    " * 97th percentile -- bottom 97% of mesures below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numpy does this well\n",
    "\n",
    "`np.percentile(array,percentile,\n",
    "               interpolation='linear')`\n",
    "\n",
    "* linear: i + (j - i) \n",
    "* fraction, where fraction is the fractional part of the index surrounded by i and j.\n",
    "* lower: i.\n",
    "* higher: j.\n",
    "* nearest: i or j, whichever is nearest.\n",
    "* midpoint: (i + j) / 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.percentile(measures,25) # the 25th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(measures,25,interpolation='higher') # bump it up to the next higher real value from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Interpercentile Range\n",
    "\n",
    "* Sometimes we want to some range\n",
    " * e.g., 5th -- 95th percentile: 90% of measures sit here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(measures,5),\"-\",np.percentile(measures,95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Variance\n",
    "\n",
    "How does the data spread around the mean?\n",
    "\n",
    "$$ variance = \\frac{\\sum{(x_i - \\mu)^2}}{n}$$\n",
    "\n",
    "where, $\\mu$ is the mean\n",
    "\n",
    "$$ mu = \\frac{\\sum{x_i}}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Standard Deviation\n",
    "\n",
    "* Measure of dispersion \n",
    "\n",
    "![standard deviation](resources/Standard_deviation_diagram.svg.png)\n",
    "(https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/640px-Standard_deviation_diagram.svg.png \"sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.percentile(measures,2.5),\"-\",np.percentile(measures,97.5))\n",
    "print(np.var(measures))\n",
    "print(np.std(measures))  # this should be the square root of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"red\">BEGIN Q3: Measures of dispersion</font>\n",
    "Examine the 2.5-97.5 percentile range and the standard deviation of your \"things\".\n",
    "Does the output for standard deviation match what you asked for when you first generated the data in Q1? What's the relationship between the 2.5th-to-97.5th percentile range and the standard deviation? Answer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">END Q3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualizing data with Seaborn\n",
    "* Visualization package built on top of matplotlib\n",
    "* It's meant to make your life better\n",
    "* Plays well with pandas, numpy, scipy, and statsmodels\n",
    "* Many different visualization are included:\n",
    " * Strip plots, Swarm plots, Violin plots\n",
    " * Box plots\n",
    " * Histograms\n",
    " \n",
    " We need to import the package, and it's typically imported as sns:\n",
    " \n",
    " ```\n",
    " import seaborn as sns\n",
    " ``` \n",
    " \n",
    " and don't forget to inline matplotlib (that's a jupyter thing):\n",
    "\n",
    " ```\n",
    " %matplotlib inline\n",
    " ```\n",
    "\n",
    "[seaborn.pydata.org](http://seaborn.pydata.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed update to 0.8 !conda update -y seaborn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Strip Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns  # you might need to do: conda install seaborn\n",
    "sns.stripplot(x=measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Swarm Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x=measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Violin Plot\n",
    "* If we have too much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=measures,color=\"#d7d0f3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=measures) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And we can manipulate the underlying plot to control different features.  See \n",
    "https://stackoverflow.com/questions/34162443/why-do-many-examples-use-fig-ax-plt-subplots-in-matplotlib-pyplot-python#34162641\n",
    "and\n",
    "https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplots for explanations about ```plt.subplots()```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11, 8)\n",
    "medianprops = dict( linewidth=2.5, color='firebrick')\n",
    "sns.boxplot(medianprops=medianprops,data=measures,orient='h')\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Histogram\n",
    "\n",
    "We're going to use this a lot.  Seaborn puts a nice smooth line over a distribution.  We'll talk about that soon, but for now just think about it as an extrapolation:  if we had a bunch more data, the distribution would eventually smooth out to something that looks like the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x axis = value, y axis = count (frequency)\n",
    "sns.distplot(measures, kde=False); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(measures, rug=True); # show a strip plot on bottom -- we call it a \"rug\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"red\">BEGIN Q4: Test driving Seaborn</font>\n",
    "Your turn:  create the above plots (strip, swarm, violin, box, and histogram for your \"things\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns  # you might need to do: conda install seaborn\n",
    "import matplotlib.pyplot as plt # in case we want to manipulate the underlying matplotlib layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose two plots from the ones you generated above and in your own words explain what each of them tells you about your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">END  Q4</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Expressiveness, Effectiveness, Scale\n",
    "\n",
    "* Expressiveness\n",
    " * What facts can we extract?\n",
    " * What facts *can't* we extract?\n",
    "* How well can we extract them?\n",
    "* How do they work with more data?\n",
    " * Consider different dimensions\n",
    " * More samples\n",
    " * More univariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we care about distributions?\n",
    "## World is not normal\n",
    "* Many other kinds of distributions\n",
    "* We can tell what they are by looking at distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = np.random.uniform(-2,2,1000)  # low,high,count\n",
    "sns.distplot(uniform,kde=False,norm_hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodal = np.append(np.random.normal(-20,10,100),\n",
    "                    np.random.normal(20,10,100))\n",
    "sns.distplot(bimodal,kde=False,norm_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(k~events~in~interval) = \\frac{\\lambda^ke^{-\\lambda}}{k!} $$\n",
    "\n",
    "$\\lambda$ is the event rate\n",
    "\n",
    "Examples\n",
    "* Meteor strikes\n",
    "* Arrival of patients to hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# as lambda goes up --> looks more normal\n",
    "pois = np.random.poisson(3,100000) # lambda, count \n",
    "sns.distplot(pois,kde=False,bins=10,norm_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Power/Zipf/Pareto\n",
    "\n",
    "$$ P = \\frac{x^{-a}}{\\zeta(a)}$$\n",
    "\n",
    "\"long tail\"\n",
    "* degree distribution\n",
    "* movie/music popularity\n",
    "* words\n",
    "\n",
    "## Note:  both axes are log-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# bit of a hack (seaborn)\n",
    "power = np.random.zipf(2,100000)\n",
    "ax = plt.plot(np.histogram(power,bins=400)[0])\n",
    "ax[0].axes.set_xscale(\"log\")\n",
    "ax[0].axes.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visual Tests on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "testdata = (np.random.standard_normal(500)*20+150).astype(int)\n",
    "sns.distplot(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Run Sequence\n",
    "* Run Sequence (index versus value)\n",
    "* flat and non-drifting\n",
    " * fixed-location assumption holds\n",
    "* vertical spread same over the entire plot, \n",
    " * then the fixed-variation assumption holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(np.arange(len(testdata)),testdata,fit_reg=False)\n",
    "ax.set_ylim(0,250)\n",
    "ax.set_ylabel(\"val\")\n",
    "ax.set_xlabel(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "drifting = np.array([testdata[i]+i*(.1) for i in np.arange(len(testdata))])\n",
    "sns.distplot(drifting,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(np.arange(len(drifting)),drifting,fit_reg=False)\n",
    "ax.set_ylim(0,300)\n",
    "ax.set_ylabel(\"val\")\n",
    "ax.set_xlabel(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "expanding = np.array([(testdata[i]+i*np.random.randint(-1,1)*.2)\n",
    "                     for i in np.arange(len(testdata))])\n",
    "sns.distplot(expanding,kde=False,norm_hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.regplot(np.arange(len(expanding)),expanding,fit_reg=False)\n",
    "ax.set_ylim(0,300)\n",
    "ax.set_ylabel(\"val\")\n",
    "ax.set_xlabel(\"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Lag Plot\n",
    "\n",
    "* Plot point $y_i$ versus $y_{i-1}$\n",
    "* If the lag plot is structureless\n",
    " * randomness assumption holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lag = testdata.copy()\n",
    "lag = np.array(lag[:-1])\n",
    "current = testdata[1:]\n",
    "ax = sns.regplot(current,lag,fit_reg=False)\n",
    "ax.set_ylabel(\"y_i-1\")\n",
    "ax.set_xlabel(\"y_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "connected = np.array([testdata[i]+testdata[i-1] for i in np.arange(500)])\n",
    "sns.distplot(connected,kde=False,norm_hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lag = connected.copy()\n",
    "lag = np.array(lag[:-1])\n",
    "current = connected[1:]\n",
    "ax = sns.regplot(current,lag,fit_reg=False)\n",
    "ax.set_ylabel(\"y_i-1\")\n",
    "ax.set_xlabel(\"y_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QQ Plot\n",
    "* QQ Plots takes our n ordered data points\n",
    " * sorted from smallest to largest\n",
    "* Asks:\n",
    " * What is the relationship between quantiles from our data and quantiles from a theoretical distribution that we're assuming the sample is drawn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "qntls, xr = stats.probplot(testdata, fit=False)\n",
    "sns.regplot(xr,qntls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def random_snorm(n, mean = 0, sd = 1, xi = 1.5):\n",
    "    def random_snorm_aux(n, xi):\n",
    "        weight = xi/(xi + 1/xi)\n",
    "        z = np.random.uniform(-weight,1-weight,n)\n",
    "        xi_ = xi**np.sign(z)\n",
    "        random = -np.absolute(np.random.normal(0,1,n))/xi_ * np.sign(z)\n",
    "        m1 = 2/np.sqrt(2 * np.pi)\n",
    "        mu = m1 * (xi - 1/xi)\n",
    "        sigma = np.sqrt((1 - m1**2) * (xi**2 + 1/xi**2) + 2 * m1**2 - 1)\n",
    "        return (random - mu)/sigma\n",
    "\n",
    "    return random_snorm_aux(n, xi) * sd + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rightskewed = random_snorm(1000,xi=2)*100\n",
    "sns.distplot(rightskewed,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "qntls, xr = stats.probplot(rightskewed, fit=False)\n",
    "sns.regplot(xr,qntls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "leftskewed = random_snorm(1000,xi=-2)*100\n",
    "sns.distplot(leftskewed,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "qntls, xr = stats.probplot(leftskewed, fit=False)\n",
    "sns.regplot(xr,qntls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">BEGIN Q5:  Are we normal?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the serious plots... let's wrap them in a single function that we can call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplePlots(series):\n",
    "    \n",
    "    fig, axs = plt.subplots(2,2)\n",
    "    plt.tight_layout(pad=0.4, w_pad=4, h_pad=1.0)\n",
    "\n",
    "    # Histogram\n",
    "    sns.distplot(series, ax=axs[0,0])\n",
    "    \n",
    "    # Lag plot code here\n",
    "    \n",
    "    # QQ plot code here\n",
    "\n",
    "    # Run Sequence doe here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run this on your \"things\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiplePlots(things)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"><a href=\"https://www.theguardian.com/news/datablog/2010/jul/16/data-plural-singular\">Do your data look</a> normally distributed?</font>\n",
    "Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normally Distributed Tomatoes\n",
    "From the above plots we can see that the randome sample of tomato weights follows a mostly normal distribution with very minimal left skewing, most likely caused by the frequency of observations under 100 grams. We find that it is mostly normally distributed because there is no visible skewing on the QQ plot either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">END Q5</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Univariate Data -- Summary\n",
    "* Simple but valuable\n",
    "* We want to know how data is distributed\n",
    "* How does it fit known models/distributions\n",
    "* When does it not?\n",
    " * Visual and analytical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">BEGIN Q6: </font>\n",
    "The sample.csv file, included with today's lab, contains 9 variables (v0 through v9) that contain\n",
    "measures drawn from different distributions.\n",
    "Your task is to use the investigative techniques we discussed in today's lab to determine\n",
    "what type of distribution the sample is drawn from.\n",
    "\n",
    "You should first load the CSV file into a DataFrame, then look at various aspects of **each** variable.\n",
    "Your responses should consist of code cells, as well as markdown cells that state something like:\n",
    "> Variable v99 appears to be drawn from a uniform distribution with mean X and standard deviation Y.  \n",
    "> A histogram of the data appears to be...\n",
    "> The QQ plot shows.... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code hre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Vizualization----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization for Data Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to ask a special virtual guest lecturer to provide some background on data visualization.  Together, we'll watch [a brief (8-video) by Dr. Chris Brooks](\n",
    "https://www.coursera.org/learn/python-plotting/lecture/qrqqa/tools-for-thinking-about-design-alberto-cairo)\n",
    "and pause it several times to answer the following questions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color=\"red\">Q1a: As someone who is studying data science, who are you trying to reach through your visualizations?  </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color=\"red\">Q1b: What sense can you make of this image?</font>\n",
    "![](resources/BrooksResearch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color=\"red\">Q1c: How many different kinds of information can you see in the Minard graphic, and what are they?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/Menard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Returning to Seaborn: \n",
    "\n",
    "https://seaborn.pydata.org/examples/index.html\n",
    "\n",
    "Take a look at the different visualizations that are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color=\"red\">Q2a: Provide the title, description, and URL of one of the visualizations that you find particularly interesting and explain why you find it interesting.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <font color=\"red\">Q2b: Given what we learned from Prof. Brooks, indicate 1-3 axes from Cairo's Visual Wheel where your chosen Seaborn visualization would likely score highly. Explain why.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/CairoVisualWheel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Seaborn versus Matplotlib\n",
    "* Matplotlib\n",
    "     * Low-level, basis for many packages\n",
    "     * Painful to construct certain graphs\n",
    "     * Not Pandas friendly\n",
    "     * Not interactive\n",
    "* Seaborn\n",
    "     * Pandas friendlier\n",
    "     * Great for some stats plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Iris dataset\n",
    "![](resources/iris.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = sns.load_dataset('iris')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our distplots:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between sepal length and width\n",
    "sns.distplot(df.sepal_length)\n",
    "sns.distplot(df.sepal_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Q3: Create similar plots for the other three numeric variables in the dataset. In a couple of sentences, describe each of the plots.  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to see how variables vary with each other.  We'll get into the details \n",
    "in a few classes, but for now let's examine them visually.  In seaborn, we do this using \n",
    "the jointplot(). So, for example, if we wanted to look at the relationship between the\n",
    "distributions of sepal_length and sepal_width, we could do something like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='sepal_length',y='sepal_width',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Q4: It's a bit difficult to see where the interesting areas in the plot are, so it's worth trying a hexbin plot.  Go ahead and copy the above  code block and add ```kind=\"hex\"``` to the jointplot parameters. In a couple of sentences, describe what stands out to you about the visualization. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a look at what happens when you set ```kind=\"kde\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='sepal_length',y='sepal_width',data=df,kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you may want to look at all the numeric variables in your\n",
    "dataset. Use ```pairplot``` to do this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.query(\"species == 'setosa'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get fancier by using a different column to set the color (or \"hue\"):\n",
    "\n",
    "Try running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's introduce some correlations.  We're not going to spend time on learning about the \n",
    "theory behind correlation, as you've done that in the statistics prerequisite for this course.\n",
    "Instead, we're going to jump right in and annotate a graph with a lot of statistical information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the warning about deprecated annotation\n",
    "g = sns.JointGrid(data=df,x='petal_length',y='sepal_length')\n",
    "g = g.plot(sns.regplot, sns.distplot)\n",
    "g = g.annotate(stats.pearsonr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about what the different components mean.  We'll return to using this in the next section on Wine Quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Wine quality\n",
    "![](resources/vinho.png)\n",
    "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('data/winequality-red.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['isgood'] = np.where(wine['quality'] > 5, 'good','bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(wine['fixed acidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Create a pairplot for the wine dataset that plots 'good' and 'bad' wines in different hues. In a couple of sentences, describe interesting relationships shown by the visualization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "naCxfhnAU2uw"
   },
   "source": [
    "## T-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A t-test is a simple statistical model that's commonly used to test whether the means of two different\n",
    "distributions are the same.  scipy.stats gives us a handy interface for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodwines = wine.query('isgood == \"good\"')\n",
    "badwines = wine.query('isgood == \"bad\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(wine[wine.isgood == 'good']['fixed acidity'],wine[wine.isgood == 'bad']['fixed acidity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Using the JointGrid approach we used above look at the relationship between sulphates and chlorides.  What patterns do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code hre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FyOXTsgU2ui"
   },
   "source": [
    "## Ordinary Least Squares (OLS) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a lot more detail about the regression model by using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1JuuPtlTU2ui"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATYDr80MU2uk"
   },
   "source": [
    "statsmodels uses R-Style formula: y ~ x1 + x2 + x3 + ...\n",
    "\n",
    "1. y represents the outcome/dependent variable\n",
    "2. x1, x2, x3, etc represent explanatory/independent variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wNqlgMXHU2uk"
   },
   "outputs": [],
   "source": [
    "model1 = smf.ols('chlorides ~ sulphates', data=wine).fit()\n",
    "model1.summary()\n",
    "\n",
    "# Commonly look at R-squared, F-statistic, coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting things happen when we use OLS to do an ANOVA (look closely at the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = smf.ols('chlorides ~ isgood', data=wine).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We might want to experiment with the original ```quality``` variable, either in a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = smf.ols('chlorides ~ quality', data=wine).fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or in an ANOVA (again, look closely at the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = smf.ols('chlorides ~ C(quality)', data=wine).fit() #Wrap it with C to convert to categorical\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMJSe5PiU2ux"
   },
   "source": [
    "## <font color=\"magenta\">Q7: Use OLS to perform either a regression or an ANOVA on a variable (other than chlorides) and interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "lzCIxjaCU2uy"
   },
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:  Airplane Crashes and Fatalities\n",
    "The next dataset we are going to look at is the full history of airplane crashes throughout the world, from 1908-2009.  It's taken from:\n",
    "\n",
    "https://opendata.socrata.com/Government/Airplane-Crashes-and-Fatalities-Since-1908/q2te-8cvq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided the CSV file for this lab so you can go ahead and load it in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes = pd.read_csv('data/Airplane_Crashes_and_Fatalities_Since_1908.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, you should take a look at the data to get a sense of \n",
    "what it's like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned in an earlier class, pandas is really good at helping\n",
    "us deal with dates.  The 'Date' column in the dataframe contains \n",
    "strings that look like dates.  We can use the ```pandas.to_datetime()``` function to convert the strings to an internal datetime object\n",
    "(see https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html for more details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes['Date'] = pd.to_datetime(crashes['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's look at the dataframe again.  See any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas datetime object makes it easy to extract interesting \n",
    "parts of the date or time.  In our case, we're interested in extracting\n",
    "the year, so we can do that with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes['year'] = crashes['Date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as always, let's look at what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes.year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the final exercise in this class, let's create a \n",
    "visualization of the number of Fatalities per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('year','Fatalities',data=crashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look great, does it?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Create a barplot of the number of fatalities per decade and describe the results. \n",
    "\n",
    "Go ahead and create a new column called 'decade' \n",
    "that represents the decade for each year.  Remember that an integer divide (a.k.a. a floor divide) can be\n",
    "done with the // operator.\n",
    "\n",
    "What's the trend in airplane crash fatalities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (FYI): Functional Magnetic Resonance Imagining\n",
    "![](resources/fmri.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri = sns.load_dataset(\"fmri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"timepoint\", y=\"signal\", kind=\"line\", data=fmri);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"timepoint\", y=\"signal\", kind=\"line\", ci=None, data=fmri);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"timepoint\", y=\"signal\", kind=\"line\", ci=\"sd\",data=fmri);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"timepoint\", y=\"signal\", kind=\"line\", estimator=None, data=fmri);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x = \"timepoint\", y = \"signal\", kind = \"line\", data = fmri, hue = \"event\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"timepoint\", y=\"signal\", kind=\"line\", data=fmri, hue=\"region\", style=\"event\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
